{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124e5672",
   "metadata": {},
   "source": [
    "# Custom Chatbot Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a94b3",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "- 2023_fashion_trends.csv (Provided with the Project)\n",
    "## Comprehensive Explanation: \n",
    "This source contains data from events from the year 2023, so the gpt-3.5-turbo-instruct model would not know about this data because it was never trained on it. Additionally, it contains references from different data sources with descriptive content and the names of the articles, which makes it easier to create specific prompts that could return different answers. Also, this dataset is not likely to change, so my chatbot will not break as it would with wikipedia articles.\n",
    "\n",
    "Other reasons include:\n",
    "\n",
    "- This dataset does not include numerical calculations or statistics for which the model is not very suitable for.\n",
    "\n",
    "- The text column was combined with the URL Source and content. This allows the model to cite sources and identify which rows below to the same source such as same url and/or same web article.\n",
    "\n",
    "- The original model was not train on the fashion trends for 2023 because its last training ended on 2021.\n",
    "\n",
    "- The content allows the model to identify fashion trends by comparing it to articles from diferent sources and interpret fashion trends during the year 2023 by observing patterns on all articles.\n",
    "\n",
    "- The results from the original model are very different from the results after training since it does not have the new data that we fed the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63d4c5f",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "\n",
    "TODO: In the cells below, load your chosen dataset into a `pandas` dataframe with a column named `\"text\"`. This column should contain all of your text data, separated into at least 20 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c69b83a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports section\n",
    "import openai\n",
    "from openai.embeddings_utils import get_embedding, distances_from_embeddings\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define Constants\n",
    "OPEN_AI_KEY = \"YOUR API KEY\"\n",
    "MAX_TOKENS = 150\n",
    "EMBEDDING_MODEL_NAME = \"text-embedding-ada-002\"\n",
    "COMPLETION_MODEL_NAME = \"gpt-3.5-turbo-instruct\"\n",
    "\n",
    "openai.api_base = \"https://openai.vocareum.com/v1\"\n",
    "openai.api_key = OPEN_AI_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5bab2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_wrangle(file_path):\n",
    "    # Read File and save data to variable\n",
    "    df = pd.read_csv(file_path , header=0)\n",
    "\n",
    "    # Combine Data into a single column named Text\n",
    "    df['text'] =  df['Source'] + ': '+ df['Trends'] + ' | ' + df['URL']\n",
    "    # Remove old columns\n",
    "    df.drop(['URL','Source', 'Trends'], axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a595980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Embeddings\n",
    "def generate_embeddings(df: pd.DataFrame, output_csv_file: str, embedding_model_name: str):\n",
    "    \"\"\"Generating Embeddings\n",
    "    We'll use the `Embedding`\n",
    "    tooling from OpenAI [documentation here](https://platform.openai.com/docs/guides/embeddings/embeddings)\n",
    "    to create vectors representing each row of our custom dataset.\"\"\"\n",
    "\n",
    "    batch_size = 100\n",
    "    embeddings = []\n",
    "    for i in range(0, len(df), batch_size):\n",
    "        # Send text data to OpenAI model to get embeddings\n",
    "        response = openai.Embedding.create(\n",
    "            input=df.iloc[i:i + batch_size][\"text\"].tolist(),\n",
    "            engine=embedding_model_name\n",
    "        )\n",
    "\n",
    "        # Add embeddings to list\n",
    "        embeddings.extend([data[\"embedding\"] for data in response[\"data\"]])\n",
    "\n",
    "    # Add embeddings list to dataframe\n",
    "    df[\"embeddings\"] = embeddings\n",
    "\n",
    "    # In order to avoid having to run that code again in the future, we'll save the generated embeddings as a CSV file.\n",
    "    df.to_csv(output_csv_file)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acb3a9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Embedding is loaded to CSV\"\n"
     ]
    }
   ],
   "source": [
    "EMBEDDINGS_FILE = './data/embeddings.csv'\n",
    "DATASET_SOURCE_FILE = './data/2023_fashion_trends.csv'\n",
    "try:\n",
    "    bot_data_frame = pd.read_csv(EMBEDDINGS_FILE, index_col=0)\n",
    "    bot_data_frame[\"embeddings\"] = bot_data_frame[\"embeddings\"].apply(eval).apply(np.array)\n",
    "except:\n",
    "    print(\"Creating Embedding and saving to CSV\")\n",
    "    # Get the Wikipedia page for \"2022\" since OpenAI's models stop in 2021\n",
    "    wrangled_dataset = load_and_wrangle(DATASET_SOURCE_FILE)\n",
    "    # Generating Embeddings\n",
    "    bot_data_frame = generate_embeddings(wrangled_dataset, EMBEDDINGS_FILE, EMBEDDING_MODEL_NAME)\n",
    "else:\n",
    "    print('\"Embedding is loaded to CSV\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae769871",
   "metadata": {},
   "source": [
    "## Custom Query Completion\n",
    "\n",
    "TODO: In the cells below, compose a custom query using your chosen dataset and retrieve results from an OpenAI `Completion` model. You may copy and paste any useful code from the course materials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "582f0656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rows_sorted_by_relevance(question, df):\n",
    "    \"\"\"\n",
    "    Function that takes in a question string and a dataframe containing\n",
    "    rows of text and associated embeddings, and returns that dataframe\n",
    "    sorted from least to most relevant for that question\n",
    "    \"\"\"\n",
    "\n",
    "    # Get embeddings for the question text\n",
    "    question_embeddings = get_embedding(question, engine=EMBEDDING_MODEL_NAME)\n",
    "\n",
    "    # Make a copy of the dataframe and add a \"distances\" column containing\n",
    "    # the cosine distances between each row's embeddings and the\n",
    "    # embeddings of the question\n",
    "    df_copy = df.copy()\n",
    "    df_copy[\"distances\"] = distances_from_embeddings(\n",
    "        question_embeddings,\n",
    "        df_copy[\"embeddings\"].values,\n",
    "        distance_metric=\"cosine\"\n",
    "    )\n",
    "\n",
    "    # Sort the copied dataframe by the distances and return it\n",
    "    # (shorter distance = more relevant so we sort in ascending order)\n",
    "    df_copy.sort_values(\"distances\", ascending=True, inplace=True)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3804a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(question, df, max_token_count):\n",
    "    \"\"\"\n",
    "    Given a question and a dataframe containing rows of text and their\n",
    "    embeddings, return a text prompt to send to a Completion model\n",
    "    \"\"\"\n",
    "    # Create a tokenizer that is designed to align with our embeddings\n",
    "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "    # Count the number of tokens in the prompt template and question\n",
    "    prompt_template = \"\"\"\n",
    "Answer the question based on the context below, and if the question\n",
    "can't be answered based on the context, say \"I don't know\"\n",
    "\n",
    "Context: \n",
    "\n",
    "{}\n",
    "\n",
    "---\n",
    "\n",
    "Question: {}\n",
    "Answer:\"\"\"\n",
    "\n",
    "    current_token_count = len(tokenizer.encode(prompt_template)) + len(tokenizer.encode(question))\n",
    "\n",
    "    context = []\n",
    "    for text in get_rows_sorted_by_relevance(question, df)[\"text\"].values:\n",
    "\n",
    "        # Increase the counter based on the number of tokens in this row\n",
    "        text_token_count = len(tokenizer.encode(text))\n",
    "        current_token_count += text_token_count\n",
    "\n",
    "        # Add the row of text to the list if we haven't exceeded the max\n",
    "        if current_token_count <= max_token_count:\n",
    "            context.append(text)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return prompt_template.format(\"\\n\\n###\\n\\n\".join(context), question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b6e1f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(\n",
    "        question, df, max_prompt_tokens=1800, max_answer_tokens=150\n",
    "):\n",
    "    \"\"\"\n",
    "    Given a question, a dataframe containing rows of text, and a maximum\n",
    "    number of desired tokens in the prompt and response, return the\n",
    "    answer to the question according to an OpenAI Completion model\n",
    "\n",
    "    If the model produces an error, return an empty string\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = create_prompt(question, df, max_prompt_tokens)\n",
    "\n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            model=COMPLETION_MODEL_NAME,\n",
    "            prompt=prompt,\n",
    "            max_tokens=max_answer_tokens\n",
    "        )\n",
    "        return response[\"choices\"][0][\"text\"].strip()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13f2dcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that answers questions directly from the model without any custom data\n",
    "def get_model_answer(prompt: str, max_tokens: int):\n",
    "    answer = openai.Completion.create(\n",
    "        model=COMPLETION_MODEL_NAME,\n",
    "        prompt=prompt,\n",
    "        max_tokens=max_tokens\n",
    "    )[\"choices\"][0][\"text\"].strip()\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c403f543",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION_1=\"\"\"\n",
    "Question: \"What jean styles are trending this spring according to fashion experts?\"\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74280b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION_2=\"\"\"\n",
    "Question: \"What styles are in vogue this summer?\"\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1783f146",
   "metadata": {},
   "source": [
    "## Custom Performance Demonstration\n",
    "\n",
    "TODO: In the cells below, demonstrate the performance of your custom query using at least 2 questions. For each question, show the answer from a basic `Completion` model query as well as the answer from your custom query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f11fdc0",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4901c850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to fashion experts, the following jean styles are trending this spring:\n",
      "\n",
      "1. Wide Leg Jeans: Wide leg jeans are making a comeback this spring, giving a nod to the 70s fashion trend. They offer a relaxed and comfortable fit that is perfect for everyday wear.\n",
      "\n",
      "2. Straight Leg Jeans: Straight leg jeans continue to be a popular style this spring. They are versatile and can be dressed up or down, making them a wardrobe staple.\n",
      "\n",
      "3. High-Waisted Jeans: High-waisted jeans are here to stay, as they offer a flattering and slimming effect. They can be found in a variety of cuts and styles, such as skinny, straight leg, and flared.\n",
      "\n",
      "4. Cropped Jeans: Cropped jeans\n"
     ]
    }
   ],
   "source": [
    "# Answer from Basic completion model to Question 1\n",
    "print(get_model_answer(QUESTION_1, MAX_TOKENS))\n",
    "# Answer from custom query to Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd7a093b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relaxed and wide-leg silhouettes.\n"
     ]
    }
   ],
   "source": [
    "# Answer from custom query to Question\n",
    "print(answer_question(QUESTION_1, bot_data_frame))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e86e37c",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f646989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Bright Colors: Bold and vibrant color palettes are in style this summer. Think sunny yellows, bright oranges, hot pinks, and electric blues.\n",
      "\n",
      "2. Floral Prints: Floral patterns are always a classic for summer fashion, and this year is no exception. Look for dainty, romantic prints or bold and tropical motifs.\n",
      "\n",
      "3. Retro Vibes: Nostalgic designs from the 60s, 70s, and 80s are making a comeback this summer. Think mini dresses, bell-bottom jeans, and oversized sunglasses.\n",
      "\n",
      "4. Flowy Silhouettes: Loose, billowy pieces like maxi dresses, flowy skirts, and wide-legged pants are perfect for summer heat. They also allow for easy movement\n"
     ]
    }
   ],
   "source": [
    "# Answer from Basic completion model to Question 2\n",
    "print(get_model_answer(QUESTION_2, MAX_TOKENS))\n",
    "# Answer from custom query to Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11c07a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From this context, we can gather that formfitting trompe l'oeil and cyber prints, painterly ombrés, PVC ruffles, white cotton, perfectly cut trousers, simplicity and everyday dressing, a trend for the inner maximalist, a return to the aesthetics of the '80s and '90s, double floral embellishments, and elevated basics, are all in vogue for summer fashion in 2023.\n"
     ]
    }
   ],
   "source": [
    "# Answer from custom query to Question\n",
    "print(answer_question(QUESTION_2, bot_data_frame))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fe9ee1",
   "metadata": {},
   "source": [
    "# Have a continous conversation with the chatbot\n",
    "\n",
    "Note: This will probably work better outside of Jupyter notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62438b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_chatting_with_bot():\n",
    "    KEEP_CHATTING = True\n",
    "\n",
    "    print('Hello, I am have to answer all your questions. Ask me anything!\\n')\n",
    "    while KEEP_CHATTING:\n",
    "        new_quetion = input('What is your question?\\n')\n",
    "        print(answer_question(new_quetion, bot_data_frame))\n",
    "        user_answer = input('Do you want to continue chatting y/n?\\n')\n",
    "        \n",
    "        if user_answer.lower() == 'n':\n",
    "            KEEP_CHATTING = False\n",
    "\n",
    "    print('It was very nice talking to you, good bye!')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d68c771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start chatting with chatbot!\n",
    "start_chatting_with_bot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e772fa",
   "metadata": {},
   "source": [
    "# Additional thoughts\n",
    "The data on which we trained the model seems to give more concise answers to our questions compared to the original model. Furthermore, the fashion trend data is specific to a season and year, so the original model has no way to pretict what would be in vogue if it was never trained on it, so this data provides exactly what it needs to give informed answers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
